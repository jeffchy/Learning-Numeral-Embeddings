{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from six import iteritems\n",
    "from web.datasets.similarity import fetch_MEN, fetch_SimLex999\n",
    "from web.embeddings import fetch_GloVe\n",
    "from web.evaluate import evaluate_similarity\n",
    "import pandas as pd\n",
    "from sklearn.datasets.base import Bunch\n",
    "import pickle\n",
    "from web.embedding import Embedding\n",
    "from web.datasets.analogy import fetch_semeval_2012_2\n",
    "from collections import defaultdict, OrderedDict\n",
    "import glob\n",
    "import os\n",
    "from six import string_types, text_type\n",
    "import numpy as np\n",
    "import scipy\n",
    "from web.evaluate import evaluate_analogy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word similarity\n",
    "WS353 = 'dataset/WS353/EN-WS353.txt'\n",
    "WSR353 = 'dataset/WS353/EN-WSR353.txt'\n",
    "MEN = 'dataset/MEN/EN-MEN-LEM.txt'\n",
    "# SIM999 = 'dataset/SIM999/EN-SIM999.txt'\n",
    "# SEMVAL2012 = 'dataset/EN-SEMVAL2012-2'\n",
    "GOOGLE = 'dataset/GOOGLE/EN-GOOGLE.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantic Part\n",
    "def fetch_dataset_WS353(path):\n",
    "    data = pd.read_csv(path, header=0, sep='\\t')\n",
    "    X = data.values[:, 0:2]\n",
    "    y = data.values[:, 2].astype(np.float)\n",
    "    data = Bunch(X=X.astype(\"object\"), y=y)\n",
    "    return data.X, data.y\n",
    "\n",
    "def fetch_dataset_MEN(path):\n",
    "    data = pd.read_csv(path, header=None, sep=' ')\n",
    "    data = data.apply(lambda x: [y if isinstance(y, float) else y[0:-2] for y in x])\n",
    "    X= data.values[:, 0:2].astype(\"object\")\n",
    "    y=data.values[:, 2:].astype(np.float) / 5.0\n",
    "    data = Bunch(X=X, y=y)\n",
    "    return data.X, data.y\n",
    "\n",
    "def fetch_dataset_SIM999(path):\n",
    "    data = pd.read_csv(path, sep='\\t')\n",
    "    X = data[['word1', 'word2']].values\n",
    "    y = data['SimLex999'].values\n",
    "    sd = data['SD(SimLex)'].values\n",
    "    conc = data[['conc(w1)', 'conc(w2)', 'concQ']].values\n",
    "    POS = data[['POS']].values\n",
    "    assoc = data[['Assoc(USF)', 'SimAssoc333']].values\n",
    "    temp = Bunch(X=X.astype(\"object\"), y=y, sd=sd, conc=conc, POS=POS, assoc=assoc)\n",
    "    return temp.X, temp.y\n",
    "\n",
    "def fetch_google_analogy(path):\n",
    "    \n",
    "    with open(path, \"r\") as f:\n",
    "        L = f.read().splitlines()\n",
    "\n",
    "    # Simple 4 word analogy questions with categories\n",
    "    questions = []\n",
    "    answers = []\n",
    "    category = []\n",
    "    cat = None\n",
    "    for l in L:\n",
    "        if l.startswith(\":\"):\n",
    "            cat =l.lower().split()[1]\n",
    "        else:\n",
    "            words =  standardize_string(l).split()\n",
    "            questions.append(words[0:3])\n",
    "            answers.append(words[3])\n",
    "            category.append(cat)\n",
    "\n",
    "    assert set(category) == set(['gram3-comparative', 'gram8-plural', 'capital-common-countries',\n",
    "                                         'city-in-state', 'family', 'gram9-plural-verbs', 'gram2-opposite',\n",
    "                                         'currency', 'gram4-superlative', 'gram6-nationality-adjective',\n",
    "                                         'gram7-past-tense',\n",
    "                                         'gram5-present-participle', 'capital-world', 'gram1-adjective-to-adverb'])\n",
    "\n",
    "\n",
    "    syntactic = set([c for c in set(category) if c.startswith(\"gram\")])\n",
    "    category_high_level = []\n",
    "    for cat in category:\n",
    "         category_high_level.append(\"syntactic\" if cat in syntactic else \"semantic\")\n",
    "\n",
    "    # dtype=object for memory efficiency\n",
    "    return Bunch(X=np.vstack(questions).astype(\"object\"),\n",
    "                 y=np.hstack(answers).astype(\"object\"),\n",
    "                 category=np.hstack(category).astype(\"object\"),\n",
    "                 category_high_level=np.hstack(category_high_level).astype(\"object\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/wikipedia/save/experiment0/idx2vec.dat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-aac2b0a2b6c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0midx2vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/wikipedia/save/experiment0/idx2vec.dat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0midx2word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/wikipedia/idx2word.dat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# assert len(idx2vec) == len(idx2word)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# idx2vec = pickle.load(open('./wordvec/nce5/idx2vec.dat', 'rb'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# idx2word = pickle.load(open('./wordvec/nce5/idx2word.dat', 'rb'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/wikipedia/save/experiment0/idx2vec.dat'"
     ]
    }
   ],
   "source": [
    "idx2vec = pickle.load(open('../data/wikipedia/save/experiment0/idx2vec.dat', 'rb'))\n",
    "idx2word = pickle.load(open('../data/wikipedia/idx2word.dat', 'rb'))\n",
    "# assert len(idx2vec) == len(idx2word)\n",
    "# idx2vec = pickle.load(open('./wordvec/nce5/idx2vec.dat', 'rb'))\n",
    "# idx2word = pickle.load(open('./wordvec/nce5/idx2word.dat', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = {idx2word[i]:idx2vec[i] for i in range(len(idx2vec))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = Embedding.from_dict(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_dataset_WS353(WS353)\n",
    "print(\"Spearman correlation of scores on {} {}\".format('WS353', evaluate_similarity(embeddings, X, y)))\n",
    "X, y = fetch_dataset_MEN(MEN)\n",
    "print(\"Spearman correlation of scores on {} {}\".format('MEN', evaluate_similarity(embeddings, X, y)))\n",
    "X, y = fetch_dataset_SIM999(SIM999)\n",
    "print(\"Spearman correlation of scores on {} {}\".format('SIM999', evaluate_similarity(embeddings, X, y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = fetch_google_analogy(GOOGLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_analogy(embeddings, data.X, data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = fetch_GloVe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_analogy(w, data.X, data.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experiment for large 0.9B dataset, dim 100, epoch 1, none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2vec = pickle.load(open('../data/wikipedia/save/experiment4large/idx2vec.dat', 'rb'))\n",
    "idx2word = pickle.load(open('../data/wikipedia/preprocess0.9B/idx2word.dat', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = {idx2word[i]:idx2vec[i] for i in range(len(idx2vec))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = Embedding.from_dict(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_dataset_WS353(WS353)\n",
    "print(\"Spearman correlation of scores on {} {}\".format('WS353', evaluate_similarity(embeddings, X, y)))\n",
    "X, y = fetch_dataset_MEN(MEN)\n",
    "print(\"Spearman correlation of scores on {} {}\".format('MEN', evaluate_similarity(embeddings, X, y)))\n",
    "X, y = fetch_dataset_SIM999(SIM999)\n",
    "print(\"Spearman correlation of scores on {} {}\".format('SIM999', evaluate_similarity(embeddings, X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experiment for large 0.9B dataset, dim 100, epoch 1, prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2vec = pickle.load(open('../data/wikipedia/save/experiment5large/idx2vec.dat', 'rb'))\n",
    "idx2word = pickle.load(open('../data/wikipedia/preprocess0.9B/idx2word.dat', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = {idx2word[i]:idx2vec[i] for i in range(len(idx2vec))}\n",
    "embeddings = Embedding.from_dict(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_dataset_WS353(WS353)\n",
    "print(\"Spearman correlation of scores on {} {}\".format('WS353', evaluate_similarity(embeddings, X, y)))\n",
    "X, y = fetch_dataset_MEN(MEN)\n",
    "print(\"Spearman correlation of scores on {} {}\".format('MEN', evaluate_similarity(embeddings, X, y)))\n",
    "X, y = fetch_dataset_SIM999(SIM999)\n",
    "print(\"Spearman correlation of scores on {} {}\".format('SIM999', evaluate_similarity(embeddings, X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experiment for small 0.05B dataset, dim 100, epoch 5, prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2vec = pickle.load(open('../data/wikipedia/save/experiment7prototypesmall/idx2vec.dat', 'rb'))\n",
    "idx2word = pickle.load(open('../data/wikipedia/preprocess0.05B/idx2word.dat', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = {idx2word[i]:idx2vec[i] for i in range(len(idx2vec))}\n",
    "embeddings = Embedding.from_dict(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_dataset_WS353(WS353)\n",
    "print(\"Spearman correlation of scores on {} {}\".format('WS353', evaluate_similarity(embeddings, X, y)))\n",
    "X, y = fetch_dataset_MEN(MEN)\n",
    "print(\"Spearman correlation of scores on {} {}\".format('MEN', evaluate_similarity(embeddings, X, y)))\n",
    "X, y = fetch_dataset_SIM999(SIM999)\n",
    "print(\"Spearman correlation of scores on {} {}\".format('SIM999', evaluate_similarity(embeddings, X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experiment for small 0.05B dataset, dim 100, epoch 5, none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2vec = pickle.load(open('../data/wikipedia/save/experiment8nonesmall/idx2vec.dat', 'rb'))\n",
    "idx2word = pickle.load(open('../data/wikipedia/preprocess0.05B/idx2word.dat', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = {idx2word[i]:idx2vec[i] for i in range(len(idx2vec))}\n",
    "embeddings = Embedding.from_dict(dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_dataset_WS353(WS353)\n",
    "print(\"Spearman correlation of scores on {} {}\".format('WS353', evaluate_similarity(embeddings, X, y)))\n",
    "X, y = fetch_dataset_MEN(MEN)\n",
    "print(\"Spearman correlation of scores on {} {}\".format('MEN', evaluate_similarity(embeddings, X, y)))\n",
    "X, y = fetch_dataset_SIM999(SIM999)\n",
    "print(\"Spearman correlation of scores on {} {}\".format('SIM999', evaluate_similarity(embeddings, X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experiments for 0.05B no table training set, dim 150, epoch 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
