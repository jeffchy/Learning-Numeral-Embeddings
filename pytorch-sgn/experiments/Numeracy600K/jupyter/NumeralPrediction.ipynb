{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../../numeral_context/')\n",
    "sys.path.append('../../../')\n",
    "sys.path.append('../../../utils/')\n",
    "sys.path.append('../../mag_num/')\n",
    "sys.path.append('../numeral_prediction/')\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from number_handler import is_numeral, to_numeral\n",
    "from tqdm import tqdm_notebook\n",
    "from create_abstract_embeddings import get_all_target_numerals, random_sample_numerals, create_magnitude_embeds\n",
    "from numeral_prediction_evaluator import Evaluator\n",
    "from numeral_to_embed import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pickle.load(open('../numeral_prediction/data.pkl','rb'))\n",
    "res = get_all_target_numerals(dataset)\n",
    "sampled_res = random_sample_numerals(res)\n",
    "pickle.dump(sampled_res, open('./magnitudes_numerals.pkl', 'wb'))\n",
    "magnitudes_numerals = pickle.load(open('./magnitudes_numerals.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = pickle.load(open('../exps/title_all_correct/word2idx.pkl', 'rb'))\n",
    "e1 = Evaluator(\n",
    "    word2idx,\n",
    "    dataset[:30000],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['2', '3', '5']:\n",
    "    trained_prototypes = pickle.load(open('../../../data/wikipedia/save/1B30W/prototypes/{}-0005/trained_prototypes_epoch1_{}00_1.0.dat'.format(i, i),'rb'))\n",
    "    embeds = [load_prototype(i, trained_prototypes) for i in magnitudes_numerals]\n",
    "    numeral_embed_i, numeral_embed_o = create_magnitude_embeds(embeds) # 8 x embed_dim\n",
    "#     pickle.dump(numeral_embed_i, open('./p{}00_i.emb'.format(i), 'wb'))\n",
    "#     pickle.dump(numeral_embed_o, open('./p{}00_o.emb'.format(i), 'wb'))\n",
    "    idx2vec_i = pickle.load(open('../exps/title_all_correct/embed/p-{}00.emb'.format(i), 'rb'))\n",
    "    idx2vec_o = pickle.load(open('../exps/title_all_correct/embed/p-{}00_o.emb'.format(i), 'rb'))\n",
    "\n",
    "    e1.load_numeral_embeds(numeral_embed_i=numeral_embed_i, numeral_embed_o=numeral_embed_o)\n",
    "    e1.load_idx2vec(idx2vec_i, idx2vec_o)\n",
    "    e1.compute_norm_factor_all(\n",
    "        pickle.load(open('../../../data/wikipedia/save/1B30W/prototypes/{}-0005/idx2vec_o_epoch1.dat'.format(i, i),'rb'))\n",
    "    )\n",
    "    ranks = e1.evaluate_avg_rank()\n",
    "    micro_f1, macro_f1 = e1.evaluate_f1()\n",
    "    result_dict['p-{}00'.format(i)] = [ranks, micro_f1, macro_f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['2', '3', '5']:\n",
    "    trained_prototypes = pickle.load(open('../../../data/wikipedia/save/1B30W/prototypes_log/{}-0005/trained_prototypes_epoch1_{}00_1.0.dat'.format(i, i),'rb'))\n",
    "    embeds = [load_prototype(i, trained_prototypes, log_space=True) for i in magnitudes_numerals]\n",
    "    numeral_embed_i, numeral_embed_o = create_magnitude_embeds(embeds) # 8 x embed_dim\n",
    "\n",
    "    idx2vec_i = pickle.load(open('../exps/title_all_correct/embed/p-{}00-log.emb'.format(i), 'rb'))\n",
    "    idx2vec_o = pickle.load(open('../exps/title_all_correct/embed/p-{}00-log_o.emb'.format(i), 'rb'))\n",
    "\n",
    "    e1.load_numeral_embeds(numeral_embed_i=numeral_embed_i, numeral_embed_o=numeral_embed_o)\n",
    "    e1.load_idx2vec(idx2vec_i, idx2vec_o)\n",
    "    e1.compute_norm_factor_all(\n",
    "        pickle.load(open('../../../data/wikipedia/save/1B30W/prototypes_log/{}-0005/idx2vec_o_epoch1.dat'.format(i, i),'rb'))\n",
    "    )\n",
    "    ranks = e1.evaluate_avg_rank()\n",
    "    micro_f1, macro_f1 = e1.evaluate_f1()\n",
    "    result_dict['p-{}00-log'.format(i)] = [ranks, micro_f1, macro_f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [('300','hard'), ('300','soft'),('500','hard'),('500','soft')]:\n",
    "    trained_prototypes = pickle.load(open('../../../data/wikipedia/save/1B30W/gmms/gmm-{}-rd-{}/trained_gmms_epoch1_{}.dat'.format(i[0], i[1], i[0]),'rb'))\n",
    "    gmm = pickle.load(open('../../../data/wikipedia/preprocess1B/NumeralAsNumeral30W/gmm/gmm-{}-rd-{}.dat'.format(i[0], i[1]),'rb'))\n",
    "\n",
    "    embeds = [load_GMM(i, trained_prototypes, gmm) for i in magnitudes_numerals]\n",
    "    numeral_embed_i, numeral_embed_o = create_magnitude_embeds(embeds) # 8 x embed_dim\n",
    "\n",
    "    idx2vec_i = pickle.load(open('../exps/title_all_correct/embed/g-{}-{}.emb'.format(i[0], i[1]), 'rb'))\n",
    "    idx2vec_o = pickle.load(open('../exps/title_all_correct/embed/g-{}-{}_o.emb'.format(i[0], i[1]), 'rb'))\n",
    "\n",
    "    e1.load_numeral_embeds(numeral_embed_i=numeral_embed_i, numeral_embed_o=numeral_embed_o)\n",
    "    e1.load_idx2vec(idx2vec_i, idx2vec_o)\n",
    "    e1.compute_norm_factor_all(\n",
    "        pickle.load(open('../../../data/wikipedia/save/1B30W/gmms/gmm-{}-rd-{}/idx2vec_o_epoch1.dat'.format(i[0], i[1]),'rb'))\n",
    "    )\n",
    "    ranks = e1.evaluate_avg_rank()\n",
    "    micro_f1, macro_f1 = e1.evaluate_f1()\n",
    "    result_dict['g-{}-{}'.format(i[0], i[1])] = [ranks, micro_f1, macro_f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [('300','hard'), ('300','soft'),('500','hard'),('500','soft')]:\n",
    "    trained_prototypes = pickle.load(open('../../../data/wikipedia/save/1B30W/gmms_log/gmm-{}-rd-{}/trained_gmms_epoch1_{}.dat'.format(i[0], i[1], i[0]),'rb'))\n",
    "    gmm = pickle.load(open('../../../data/wikipedia/preprocess1B/NumeralAsNumeral30W/gmm_log/gmm-{}-rd-{}.dat'.format(i[0], i[1]),'rb'))\n",
    "\n",
    "    embeds = [load_GMM(i, trained_prototypes, gmm, log_space=True) for i in magnitudes_numerals]\n",
    "    numeral_embed_i, numeral_embed_o = create_magnitude_embeds(embeds) # 8 x embed_dim\n",
    "\n",
    "    idx2vec_i = pickle.load(open('../exps/title_all_correct/embed/g-{}-{}-log.emb'.format(i[0], i[1]), 'rb'))\n",
    "    idx2vec_o = pickle.load(open('../exps/title_all_correct/embed/g-{}-{}-log_o.emb'.format(i[0], i[1]), 'rb'))\n",
    "\n",
    "    e1.load_numeral_embeds(numeral_embed_i=numeral_embed_i, numeral_embed_o=numeral_embed_o)\n",
    "    e1.load_idx2vec(idx2vec_i, idx2vec_o)\n",
    "    e1.compute_norm_factor_all(\n",
    "        pickle.load(open('../../../data/wikipedia/save/1B30W/gmms_log/gmm-{}-rd-{}/idx2vec_o_epoch1.dat'.format(i[0], i[1]),'rb'))\n",
    "    )\n",
    "    ranks = e1.evaluate_avg_rank()\n",
    "    micro_f1, macro_f1 = e1.evaluate_f1()\n",
    "    result_dict['g-{}-{}-log'.format(i[0], i[1])] = [ranks, micro_f1, macro_f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "ivec = pickle.load(open('../../../data/wikipedia/save/1B30W/token/idx2vec_i_epoch1.dat','rb'))\n",
    "ovec = pickle.load(open('../../../data/wikipedia/save/1B30W/token/idx2vec_o_epoch1.dat','rb'))\n",
    "w2i = pickle.load(open('../../../data/wikipedia/preprocess1B/NumeralAsTokenUnkNumeral30W/word2idx.dat','rb'))\n",
    "embeds = [load_TOKEN(i, ivec, ovec, w2i) for i in magnitudes_numerals]\n",
    "numeral_embed_i, numeral_embed_o = create_magnitude_embeds(embeds) # 8 x embed_dim\n",
    "\n",
    "idx2vec_i = pickle.load(open('../exps/title_all_correct/embed/token.emb', 'rb'))\n",
    "idx2vec_o = pickle.load(open('../exps/title_all_correct/embed/token_o.emb', 'rb'))\n",
    "\n",
    "e1.load_numeral_embeds(numeral_embed_i=numeral_embed_i, numeral_embed_o=numeral_embed_o)\n",
    "e1.load_idx2vec(idx2vec_i, idx2vec_o)\n",
    "e1.compute_norm_factor_all(\n",
    "    pickle.load(open('../../../data/wikipedia/save/1B30W/token/idx2vec_o_epoch1.dat','rb'))\n",
    ")\n",
    "ranks = e1.evaluate_avg_rank()\n",
    "micro_f1, macro_f1 = e1.evaluate_f1()\n",
    "result_dict['token'] =  [ranks, micro_f1, macro_f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../../../data/wikipedia/save/1B30W/LSTM/sgns_epoch1.pt'\n",
    "# embeds = [load_LSTM(i, model_path, 300) for i in magnitudes_numerals]\n",
    "# numeral_embed_i, numeral_embed_o = create_magnitude_embeds(embeds) # 8 x embed_dim\n",
    "# pickle.dump(numeral_embed_i, open('./LSTM_i.emb', 'wb'))\n",
    "# pickle.dump(numeral_embed_o, open('./LSTM_o.emb', 'wb'))\n",
    "numeral_embed_i = pickle.load(open('./LSTM_i.emb', 'rb'))\n",
    "numeral_embed_o = pickle.load(open('./LSTM_o.emb', 'rb'))\n",
    "idx2vec_i = pickle.load(open('../exps/title_all_correct/embed/LSTM.emb', 'rb'))\n",
    "idx2vec_o = pickle.load(open('../exps/title_all_correct/embed/LSTM_o.emb', 'rb'))\n",
    "\n",
    "e1.load_numeral_embeds(numeral_embed_i=numeral_embed_i, numeral_embed_o=numeral_embed_o)\n",
    "e1.load_idx2vec(idx2vec_i, idx2vec_o)\n",
    "e1.compute_norm_factor_all(\n",
    "    pickle.load(open('../../../data/wikipedia/save/1B30W/LSTM/idx2vec_o_epoch1.dat','rb'))\n",
    ")\n",
    "ranks = e1.evaluate_avg_rank()\n",
    "micro_f1, macro_f1 = e1.evaluate_f1()\n",
    "result_dict['LSTM'] =  [ranks, micro_f1, macro_f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = [load_fixed(i, 300) for i in magnitudes_numerals]\n",
    "numeral_embed_i, numeral_embed_o = create_magnitude_embeds(embeds) # 8 x embed_dim\n",
    "\n",
    "idx2vec_i = pickle.load(open('../exps/title_all_correct/embed/Fixed.emb', 'rb'))\n",
    "idx2vec_o = pickle.load(open('../exps/title_all_correct/embed/Fixed_o.emb', 'rb'))\n",
    "\n",
    "e1.load_numeral_embeds(numeral_embed_i=numeral_embed_i, numeral_embed_o=numeral_embed_o)\n",
    "e1.load_idx2vec(idx2vec_i, idx2vec_o)\n",
    "e1.compute_norm_factor_all(\n",
    "    pickle.load(open('../../../data/wikipedia/save/1B30W/FIXED/idx2vec_o_epoch1.dat','rb'))\n",
    ")\n",
    "ranks = e1.evaluate_avg_rank()\n",
    "micro_f1, macro_f1 = e1.evaluate_f1()\n",
    "result_dict['Fixed'] =  [ranks, micro_f1, macro_f1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p-200</th>\n",
       "      <td>2.657667</td>\n",
       "      <td>0.334500</td>\n",
       "      <td>0.199259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p-300</th>\n",
       "      <td>2.687867</td>\n",
       "      <td>0.343533</td>\n",
       "      <td>0.206581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p-500</th>\n",
       "      <td>2.661467</td>\n",
       "      <td>0.344900</td>\n",
       "      <td>0.208049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p-200-log</th>\n",
       "      <td>2.663867</td>\n",
       "      <td>0.347433</td>\n",
       "      <td>0.204337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p-300-log</th>\n",
       "      <td>2.598000</td>\n",
       "      <td>0.345367</td>\n",
       "      <td>0.238360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p-500-log</th>\n",
       "      <td>2.647200</td>\n",
       "      <td>0.347567</td>\n",
       "      <td>0.206107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g-300-hard</th>\n",
       "      <td>2.620933</td>\n",
       "      <td>0.352433</td>\n",
       "      <td>0.213434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g-300-soft</th>\n",
       "      <td>2.568900</td>\n",
       "      <td>0.346067</td>\n",
       "      <td>0.244394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g-500-hard</th>\n",
       "      <td>2.539267</td>\n",
       "      <td>0.350233</td>\n",
       "      <td>0.250076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g-500-soft</th>\n",
       "      <td>2.575733</td>\n",
       "      <td>0.350733</td>\n",
       "      <td>0.208335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g-300-hard-log</th>\n",
       "      <td>2.631333</td>\n",
       "      <td>0.343133</td>\n",
       "      <td>0.253023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g-300-soft-log</th>\n",
       "      <td>2.602500</td>\n",
       "      <td>0.342633</td>\n",
       "      <td>0.245788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g-500-hard-log</th>\n",
       "      <td>2.560900</td>\n",
       "      <td>0.348233</td>\n",
       "      <td>0.264307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g-500-soft-log</th>\n",
       "      <td>2.579200</td>\n",
       "      <td>0.343167</td>\n",
       "      <td>0.243604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <td>2.802300</td>\n",
       "      <td>0.323900</td>\n",
       "      <td>0.194815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM</th>\n",
       "      <td>6.022700</td>\n",
       "      <td>0.021967</td>\n",
       "      <td>0.030220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fixed</th>\n",
       "      <td>3.376333</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0         1         2\n",
       "p-200           2.657667  0.334500  0.199259\n",
       "p-300           2.687867  0.343533  0.206581\n",
       "p-500           2.661467  0.344900  0.208049\n",
       "p-200-log       2.663867  0.347433  0.204337\n",
       "p-300-log       2.598000  0.345367  0.238360\n",
       "p-500-log       2.647200  0.347567  0.206107\n",
       "g-300-hard      2.620933  0.352433  0.213434\n",
       "g-300-soft      2.568900  0.346067  0.244394\n",
       "g-500-hard      2.539267  0.350233  0.250076\n",
       "g-500-soft      2.575733  0.350733  0.208335\n",
       "g-300-hard-log  2.631333  0.343133  0.253023\n",
       "g-300-soft-log  2.602500  0.342633  0.245788\n",
       "g-500-hard-log  2.560900  0.348233  0.264307\n",
       "g-500-soft-log  2.579200  0.343167  0.243604\n",
       "token           2.802300  0.323900  0.194815\n",
       "LSTM            6.022700  0.021967  0.030220\n",
       "Fixed           3.376333  0.000133  0.000822"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e1.show_scores(result_dict, 0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
